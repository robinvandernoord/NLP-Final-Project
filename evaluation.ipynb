{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# String Similarity"
      ],
      "metadata": {
        "id": "4TGj_fsYyjuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RErgXZfUyfko",
        "outputId": "c4aee87c-047e-411a-c40a-c083818efb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 14.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "uTFQ4ge9y5Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the answer to string, return metrics in last step: return []\n"
      ],
      "metadata": {
        "id": "YOxIEyHO9kR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing \n",
        "def normalize_text(s):\n",
        "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "    import string, re\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "metadata": {
        "id": "qwQd5qwG9IgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "predictions = tf.ragged.constant([['captain', 'of', 'the', 'delta', 'flight']])\n",
        "gold_answers = tf.ragged.constant([['delta', 'air', 'lines', 'flight']])"
      ],
      "metadata": {
        "id": "E7exVzQx0yiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = text.metrics.rouge_l(predictions, gold_answers)\n",
        "print('F-Measure: %s' % result.f_measure)\n",
        "print('P-Measure: %s' % result.p_measure)\n",
        "print('R-Measure: %s' % result.r_measure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2imnJJx1Ua5",
        "outputId": "3b53d15e-d72c-4ae6-de7a-c01b337237db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Measure: tf.Tensor([0.44444448], shape=(1,), dtype=float32)\n",
            "P-Measure: tf.Tensor([0.4], shape=(1,), dtype=float32)\n",
            "R-Measure: tf.Tensor([0.5], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the alpha"
      ],
      "metadata": {
        "id": "06t9_GLy4wsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ZnjOIgKnnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98d7a31-aaa1-4b5a-cd7a-670dac34dc61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Measure (alpha=0): tf.Tensor([0.5 0.5], shape=(2,), dtype=float32)\n",
            "P-Measure (alpha=0): tf.Tensor([0.4       0.6666667], shape=(2,), dtype=float32)\n",
            "R-Measure (alpha=0): tf.Tensor([0.5 0.5], shape=(2,), dtype=float32)\n",
            "F-Measure (alpha=1): tf.Tensor([0.4       0.6666667], shape=(2,), dtype=float32)\n",
            "P-Measure (alpha=1): tf.Tensor([0.4       0.6666667], shape=(2,), dtype=float32)\n",
            "R-Measure (alpha=1): tf.Tensor([0.5 0.5], shape=(2,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Compute ROUGE-L with alpha=0\n",
        "result = text.metrics.rouge_l(predictions, gold_answers, alpha=0)\n",
        "print('F-Measure (alpha=0): %s' % result.f_measure)\n",
        "print('P-Measure (alpha=0): %s' % result.p_measure)\n",
        "print('R-Measure (alpha=0): %s' % result.r_measure)\n",
        "result = text.metrics.rouge_l(predictions, gold_answers, alpha=1)\n",
        "print('F-Measure (alpha=1): %s' % result.f_measure)\n",
        "print('P-Measure (alpha=1): %s' % result.p_measure)\n",
        "print('R-Measure (alpha=1): %s' % result.r_measure)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative: Exact Match and F1\n",
        "\n"
      ],
      "metadata": {
        "id": "_xMUnYEc42iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def get_gold_answers(example):\n",
        "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
        "    \n",
        "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
        "\n",
        "    # if gold_answers doesn't exist it's because this is a negative example - \n",
        "    # the only correct answer is an empty string\n",
        "    if not gold_answers:\n",
        "        gold_answers = [\"\"]\n",
        "        \n",
        "    return gold_answers"
      ],
      "metadata": {
        "id": "hi1TNYPs8dSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "gold_answers = []"
      ],
      "metadata": {
        "id": "MhazkeU49dtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "em_score = max((compute_exact_match(predictions, gold_answers) for answer in gold_answers)\n",
        "f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
        "\n",
        "\n",
        "print(f\"EM: {em_score} \\t F1: {f1_score}\")"
      ],
      "metadata": {
        "id": "Pi0VLDLh5XQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}